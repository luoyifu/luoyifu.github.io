---
layout:     post
title:      "深度学习基础知识"
subtitle:   "需要了解的关于深度学习的知识和概念"
date:       2018-05-31 12:00:00
author:     "Luo Yifu"
header-img: "img/post-bg-2015.jpg"
tags:
    - deeplearning
---

# 深度学习基础知识

## 符号计算
符号主义的计算首先定义各种变量，然后建立一个“计算图”，计算图规定了各个变量之间的计算关系。建立好的计算图需要编译以确定其内部细节，然而，此时的计算图还是一个“空壳子”，里面没有任何实际的数据，只有当你把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。
TensorFlow和Theano都是基于符号计算。

Keras的模型搭建形式也是这种方法，在你搭建Keras模型完毕后，你的模型就是一个空壳子，只有实际生成可调用的函数后（K.function），输入数据，才会形成真正的数据流。

## 张量
张量，或tensor。张量可以看作是向量、矩阵的自然推广，我们用张量来表示广泛的数据类型。

规模最小的张量是0阶张量，即标量，也就是一个数。当我们把一些数有序的排列起来，就形成了1阶张量，也就是一个向量。如果我们继续把一组向量有序的排列起来，就形成了2阶张量，也就是一个矩阵。把矩阵摞起来，就是3阶张量，我们可以称为一个立方体，具有3个颜色通道的彩色图片就是一个这样的立方体。把立方体摞起来，就叫4阶张量了，不要去试图想像4阶张量是什么样子，它就是个数学上的概念。

张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文axis。譬如一个矩阵[[1,2],[3,4]]，是一个2阶张量，有两个维度或轴，沿着第0个轴（为了与python的计数方式一致，本文档维度和轴从0算起）你看到的是[1,2]，[3,4]两个向量（每一行是一个向量，可以看成是沿x轴看来），沿着第1个轴你看到的是[1,3]，[2,4]两个向量（每一列是一个向量）。

要理解“沿着某个轴”是什么意思，不妨试着运行一下下面的代码：
```
import numpy as np

a = np.array([[1,2],[3,4]])
sum0 = np.sum(a, axis=0)
sum1 = np.sum(a, axis=1)

print sum0
print sum1
```

## Softmax回归
softmax用于多分类过程中，它将多个神经元的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类。
![img](/img/in-post/softmax.jpg)
以上图为例，softmax直白来说就是将原来输出是3,1,-3通过softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标

TensorFlow官方文档MNIST数据的例子：
MNIST的每一张图片都表示一个数字，从0到9。我们希望得到给定图片代表每个数字的概率。比如说，我们的模型可能推测一张包含9的图片代表数字9的概率是80%但是判断它是8的概率是5%（因为8和9都有上半部分的小圆），然后给予它代表其他数字的概率更小的值。
因此对于给定的输入图片 x 它代表的是数字 i 的证据可以表示为：
evidence_i=sum[x=j](w_ij*x_j+b_i)
y=softmax(evidence)

参考资料
[详解Softmax函数](https://zhuanlan.zhihu.com/p/25723112)

## 损失函数（loss function）和代价函数(cost function)

1.损失函数(Loss function)是定义在**单个训练样本**上的，也就是就算一个样本的误差，比如我们想要分类，就是预测的类别和实际类别的区别，是一个样本的哦，用L表示

2.代价函数(Cost function)是定义在**整个训练集**上面的，也就是所有样本的误差的总和的平均，也就是损失函数的总和的平均，有没有这个平均其实不会影响最后的参数的求解结果。

假设有训练样本(x, y)，模型为h，参数为θ。$ h(θ) = {θ^T}x $ （θT表示θ的转置）。
**简单来讲，任何能够衡量模型预测出来的值h(θ)与真实值y之间的差异的函数都可以叫做代价函数C(θ)**，如果有多个样本，则可以将所有代价函数的取值求均值，记做J(θ)。

### 常见的代价函数：
1. 均方误差

$$
J(\theta_0, \theta_1) = \frac{ 1 }{ 2m } \displaystyle \sum_{ i = 1 }^{ m } (\hat{ y }^{(i)} - y^{(i)})^2 = \frac{ 1 }{ 2m } \displaystyle \sum_{ i = 1 }^{ m } (h_\theta(x^{(i)}) - y^{(i)})^2
$$

2. 交叉熵
在逻辑回归中，最常用的是代价函数是交叉熵(Cross Entropy)，在神经网络中也会用到。
> 交叉熵是对「出乎意料」（译者注：原文使用suprise）的度量。神经元的目标是去计算函数y, 且y=y(x)。但是我们让它取而代之计算函数a, 且a=a(x)。假设我们把a当作y等于1的概率，1−a是y等于0的概率。那么，交叉熵衡量的是我们在知道y的真实值时的平均「出乎意料」程度。当输出是我们期望的值，我们的「出乎意料」程度比较低；当输出不是我们期望的，我们的「出乎意料」程度就比较高。

$$
J(\theta) = -\frac{ 1 }{ m }[\sum_{ i=1 }^{ m } ({y^{(i)} \log h_\theta(x^{(i)}) + (1-y^{(i)}) \log (1-h_\theta(x^{(i)})})]
$$

## 梯度下降法
在机器学习的很多**监督学习模型**中，需要对原始模型构建损失函数，然后优化损失函数找到最有参数。在参数优化中，使用较多的是梯度下降算法（Gradient Descent,GD）。
> 直观的理解是：从山上某一点出发，找一个最陡的坡（梯度方向）走一步，到达下一个点后，再找一个最陡的坡，直到走到最低点（最小花费函数收敛点）

## batch
batch可以翻译为“一批，批量”。可以理解为数据的量。
深度学习的优化算法，说白了就是梯度下降(Gradient Descent, GD)。每次的参数更新有3种方式。

1. 批梯度下降法（batch gradient descent, BGD）:遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度。
这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习。
> 每迭代一步，都要用到训练集所有的数据，如果样本数目很大，那么可想而知这种方法的迭代速度！ 
> 优点：全局最优解；易于并行实现； 
> 缺点：当样本数目很多时，训练过程会很慢。 

2. 随机梯度下降法（stochastic gradient descent, SGD）:每次仅根据一个样本对模型参数进行调整（即每看一个数据就算一下损失函数，然后求梯度更新参数）。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。
> 优点：训练速度快； 
> 缺点：准确度下降，并不是全局最优；不易于并行实现。 
> 从迭代的次数上来看，SGD迭代的次数较多，在解空间的搜索过程看起来很盲目。

3. 小批量梯度下降法（mini-batch gradient descent, MBGD）:为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。
> 假设训练集中的样本的个数为1000，则每个mini-batch只是其一个子集，假设，每个mini-batch中含有10个样本，这样，整个训练数据集可以分为100个mini-batch。

基本上现在的梯度下降都是基于mini-batch的，所以Keras的模块中经常会出现batch_size，就是指这个。

顺便说一句，Keras中用的优化器SGD是stochastic gradient descent的缩写，但不代表是一个样本就更新一回，还是基于mini-batch的。

## 激励函数
**激励函数（activation function）**，也被翻译为 **激活函数** ，激励函数一般用于神经网络的层与层之间，上一层的输出通过激励函数的转换之后输入到下一层中。神经网络模型是非线性的，如果没有使用激励函数，那么每一层实际上都相当于矩阵相乘。经过非线性的激励函数作用，使得神经网络有了更多的表现力。
常见的激励函数图像：
![常见激励函数](/img/in-post/jihuohanshu.png)

[激励函数的作用_颜沁睿](https://www.zhihu.com/question/22334626/answer/103835591)
[不同的激励函数](https://blog.csdn.net/dabokele/article/details/58713727)